{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc33bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Import necessary libraries\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a9ff38",
   "metadata": {},
   "source": [
    "We open the data and prepare it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9cc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./datosImputados_con_XGBOOST.csv\")\n",
    "train_scores = pd.read_csv('./Y_train_1rknArQ.csv', index_col=0)\n",
    "train_data_con_resultado =  pd.concat([train_data,train_scores],join='inner',axis=1) # Join together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53478ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función que transforme el resultado\n",
    "def transform_result(row):\n",
    "    if row['HOME_WINS'] == 1:\n",
    "        return 'win'\n",
    "    elif row['DRAW'] == 1:\n",
    "        return 'draw'\n",
    "    else:\n",
    "        return 'lose'\n",
    "\n",
    "# Aplica la función a cada fila del DataFrame\n",
    "train_data_con_resultado['RESULT'] = train_data_con_resultado.apply(transform_result, axis=1)\n",
    "\n",
    "train_data_con_resultado.drop(['HOME_WINS', 'DRAW', 'AWAY_WINS'], axis=1, inplace=True)\n",
    "train_data_con_resultado.to_csv('train_data_limpios_XGBOOST.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e849192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que tu DataFrame se llama df\n",
    "df = pd.read_csv(\"train_data_limpios_XGBOOST.csv\")  # Asegúrate de cargar tu archivo correctamente\n",
    "\n",
    "# Preparar los datos\n",
    "X = df.drop('RESULT', axis=1)  # Reemplaza 'columna_objetivo' con el nombre de tu columna de objetivo\n",
    "y = df['RESULT']  # Esto es la columna con los valores 'lose', 'win', 'draw'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7548d",
   "metadata": {},
   "source": [
    "Once we have the data as we want, we scale the data and divide it between training and test, 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acdfc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7121e3",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa994f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de Regresión Logística: 0.41\n"
     ]
    }
   ],
   "source": [
    "# Entrenar un modelo de Regresión Logística\n",
    "logreg = LogisticRegression(solver='saga', max_iter=10000, random_state=42)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test_scaled)\n",
    "acc_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "print(f'Accuracy de Regresión Logística: {acc_logreg:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7d42f8",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c2135c",
   "metadata": {},
   "source": [
    "We have tested different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a88aee85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 1.1392 - accuracy: 0.3781 - val_loss: 1.1023 - val_accuracy: 0.3976\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0476 - accuracy: 0.4576 - val_loss: 1.1226 - val_accuracy: 0.3932\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 1.0067 - accuracy: 0.4925 - val_loss: 1.1344 - val_accuracy: 0.3844\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9700 - accuracy: 0.5253 - val_loss: 1.1587 - val_accuracy: 0.3899\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.9256 - accuracy: 0.5689 - val_loss: 1.1807 - val_accuracy: 0.3789\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8787 - accuracy: 0.5978 - val_loss: 1.2128 - val_accuracy: 0.3811\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.8248 - accuracy: 0.6392 - val_loss: 1.2791 - val_accuracy: 0.3601\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7769 - accuracy: 0.6612 - val_loss: 1.3450 - val_accuracy: 0.3767\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.6953 - val_loss: 1.3812 - val_accuracy: 0.3425\n",
      "Epoch 10/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.7198 - val_loss: 1.4545 - val_accuracy: 0.3502\n",
      "Epoch 11/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6285 - accuracy: 0.7462 - val_loss: 1.5511 - val_accuracy: 0.3524\n",
      "Epoch 12/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5828 - accuracy: 0.7706 - val_loss: 1.5990 - val_accuracy: 0.3833\n",
      "Epoch 13/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5458 - accuracy: 0.7867 - val_loss: 1.7321 - val_accuracy: 0.3546\n",
      "Epoch 14/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.8070 - val_loss: 1.7654 - val_accuracy: 0.3711\n",
      "Epoch 15/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.8291 - val_loss: 1.8500 - val_accuracy: 0.3480\n",
      "Epoch 16/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8402 - val_loss: 2.0042 - val_accuracy: 0.3623\n",
      "Epoch 17/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8582 - val_loss: 2.0796 - val_accuracy: 0.3546\n",
      "Epoch 18/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.3607 - accuracy: 0.8763 - val_loss: 2.1417 - val_accuracy: 0.3392\n",
      "Epoch 19/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8921 - val_loss: 2.2812 - val_accuracy: 0.3590\n",
      "Epoch 20/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8993 - val_loss: 2.3733 - val_accuracy: 0.3403\n",
      "Epoch 21/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.2802 - accuracy: 0.9084 - val_loss: 2.5234 - val_accuracy: 0.3458\n",
      "Epoch 22/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.9246 - val_loss: 2.5888 - val_accuracy: 0.3546\n",
      "Epoch 23/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9363 - val_loss: 2.7288 - val_accuracy: 0.3469\n",
      "Epoch 24/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.2080 - accuracy: 0.9389 - val_loss: 2.9171 - val_accuracy: 0.3315\n",
      "Epoch 25/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.9434 - val_loss: 3.0253 - val_accuracy: 0.3469\n",
      "Epoch 26/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.1651 - accuracy: 0.9590 - val_loss: 3.1744 - val_accuracy: 0.3414\n",
      "Epoch 27/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9651 - val_loss: 3.2585 - val_accuracy: 0.3293\n",
      "Epoch 28/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9712 - val_loss: 3.4420 - val_accuracy: 0.3260\n",
      "Epoch 29/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9731 - val_loss: 3.6130 - val_accuracy: 0.3403\n",
      "Epoch 30/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9716 - val_loss: 3.7272 - val_accuracy: 0.3381\n",
      "Epoch 31/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9748 - val_loss: 3.7495 - val_accuracy: 0.3425\n",
      "Epoch 32/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9623 - val_loss: 3.8425 - val_accuracy: 0.3425\n",
      "Epoch 33/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9609 - val_loss: 3.9748 - val_accuracy: 0.3293\n",
      "Epoch 34/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.9844 - val_loss: 4.1371 - val_accuracy: 0.3315\n",
      "Epoch 35/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9935 - val_loss: 4.2942 - val_accuracy: 0.3381\n",
      "Epoch 36/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9982 - val_loss: 4.4190 - val_accuracy: 0.3304\n",
      "Epoch 37/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9996 - val_loss: 4.5263 - val_accuracy: 0.3348\n",
      "Epoch 38/50\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9998 - val_loss: 4.6900 - val_accuracy: 0.3282\n",
      "Epoch 39/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 4.7894 - val_accuracy: 0.3370\n",
      "Epoch 40/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 4.9224 - val_accuracy: 0.3271\n",
      "Epoch 41/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9998 - val_loss: 5.0646 - val_accuracy: 0.3282\n",
      "Epoch 42/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.9013 - val_loss: 4.8884 - val_accuracy: 0.3348\n",
      "Epoch 43/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8884 - val_loss: 4.7956 - val_accuracy: 0.3381\n",
      "Epoch 44/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9678 - val_loss: 4.9056 - val_accuracy: 0.3315\n",
      "Epoch 45/50\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.0384 - accuracy: 0.9958 - val_loss: 4.9619 - val_accuracy: 0.3227\n",
      "Epoch 46/50\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9998 - val_loss: 5.0637 - val_accuracy: 0.3392\n",
      "Epoch 47/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 5.1643 - val_accuracy: 0.3337\n",
      "Epoch 48/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 5.2422 - val_accuracy: 0.3370\n",
      "Epoch 49/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 5.3035 - val_accuracy: 0.3370\n",
      "Epoch 50/50\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 5.3931 - val_accuracy: 0.3293\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 5.1409 - accuracy: 0.3455\n",
      "Accuracy de la Red Neuronal: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Crear el objeto LabelEncoder y transformar las etiquetas de texto a numéricas\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "# Codificar las etiquetas numéricas como one-hot\n",
    "y_train_onehot = to_categorical(y_train_encoded)\n",
    "y_test_onehot = to_categorical(y_test_encoded)\n",
    "\n",
    "# Construir el modelo de red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y_train_onehot.shape[1], activation='softmax'))  # El número de neuronas en la capa de salida corresponde al número de clases\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train_scaled, y_train_onehot, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluar el modelo\n",
    "_, acc_nn = model.evaluate(X_test_scaled, y_test_onehot)\n",
    "print(f'Accuracy de la Red Neuronal: {acc_nn:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4adc23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "511/511 [==============================] - 3s 3ms/step - loss: 1.1562 - accuracy: 0.3826 - val_loss: 1.0888 - val_accuracy: 0.4097\n",
      "Epoch 2/100\n",
      "511/511 [==============================] - 1s 3ms/step - loss: 1.0945 - accuracy: 0.4055 - val_loss: 1.0805 - val_accuracy: 0.4339\n",
      "Epoch 3/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0858 - accuracy: 0.4219 - val_loss: 1.0796 - val_accuracy: 0.4317\n",
      "Epoch 4/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0797 - accuracy: 0.4288 - val_loss: 1.0799 - val_accuracy: 0.4317\n",
      "Epoch 5/100\n",
      "511/511 [==============================] - 2s 4ms/step - loss: 1.0793 - accuracy: 0.4311 - val_loss: 1.0761 - val_accuracy: 0.4317\n",
      "Epoch 6/100\n",
      "511/511 [==============================] - 2s 5ms/step - loss: 1.0788 - accuracy: 0.4315 - val_loss: 1.0787 - val_accuracy: 0.4317\n",
      "Epoch 7/100\n",
      "511/511 [==============================] - 2s 4ms/step - loss: 1.0750 - accuracy: 0.4349 - val_loss: 1.0770 - val_accuracy: 0.4317\n",
      "Epoch 8/100\n",
      "511/511 [==============================] - 2s 3ms/step - loss: 1.0759 - accuracy: 0.4318 - val_loss: 1.0756 - val_accuracy: 0.4317\n",
      "Epoch 9/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0741 - accuracy: 0.4331 - val_loss: 1.0741 - val_accuracy: 0.4317\n",
      "Epoch 10/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0746 - accuracy: 0.4332 - val_loss: 1.0765 - val_accuracy: 0.4317\n",
      "Epoch 11/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0717 - accuracy: 0.4332 - val_loss: 1.0741 - val_accuracy: 0.4317\n",
      "Epoch 12/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0737 - accuracy: 0.4321 - val_loss: 1.0749 - val_accuracy: 0.4317\n",
      "Epoch 13/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0715 - accuracy: 0.4345 - val_loss: 1.0773 - val_accuracy: 0.4317\n",
      "Epoch 14/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0716 - accuracy: 0.4333 - val_loss: 1.0765 - val_accuracy: 0.4317\n",
      "Epoch 15/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0680 - accuracy: 0.4358 - val_loss: 1.0760 - val_accuracy: 0.4317\n",
      "Epoch 16/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0650 - accuracy: 0.4326 - val_loss: 1.0791 - val_accuracy: 0.4317\n",
      "Epoch 17/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0648 - accuracy: 0.4334 - val_loss: 1.0825 - val_accuracy: 0.4339\n",
      "Epoch 18/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0648 - accuracy: 0.4342 - val_loss: 1.0800 - val_accuracy: 0.4317\n",
      "Epoch 19/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 1.0624 - accuracy: 0.4353 - val_loss: 1.0813 - val_accuracy: 0.4317\n",
      "Epoch 20/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0581 - accuracy: 0.4355 - val_loss: 1.0811 - val_accuracy: 0.4306\n",
      "Epoch 21/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0575 - accuracy: 0.4340 - val_loss: 1.0816 - val_accuracy: 0.4317\n",
      "Epoch 22/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0523 - accuracy: 0.4375 - val_loss: 1.0842 - val_accuracy: 0.4262\n",
      "Epoch 23/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0514 - accuracy: 0.4419 - val_loss: 1.0857 - val_accuracy: 0.4251\n",
      "Epoch 24/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0484 - accuracy: 0.4407 - val_loss: 1.0863 - val_accuracy: 0.4174\n",
      "Epoch 25/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0472 - accuracy: 0.4431 - val_loss: 1.0889 - val_accuracy: 0.4174\n",
      "Epoch 26/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 1.0437 - accuracy: 0.4461 - val_loss: 1.0883 - val_accuracy: 0.4284\n",
      "Epoch 27/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0423 - accuracy: 0.4430 - val_loss: 1.0867 - val_accuracy: 0.4229\n",
      "Epoch 28/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0353 - accuracy: 0.4479 - val_loss: 1.0901 - val_accuracy: 0.3932\n",
      "Epoch 29/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0370 - accuracy: 0.4474 - val_loss: 1.0902 - val_accuracy: 0.4097\n",
      "Epoch 30/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0314 - accuracy: 0.4621 - val_loss: 1.0885 - val_accuracy: 0.4064\n",
      "Epoch 31/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0250 - accuracy: 0.4524 - val_loss: 1.0900 - val_accuracy: 0.3899\n",
      "Epoch 32/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0273 - accuracy: 0.4607 - val_loss: 1.0942 - val_accuracy: 0.3744\n",
      "Epoch 33/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0197 - accuracy: 0.4659 - val_loss: 1.0997 - val_accuracy: 0.3722\n",
      "Epoch 34/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0225 - accuracy: 0.4643 - val_loss: 1.0942 - val_accuracy: 0.3689\n",
      "Epoch 35/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0118 - accuracy: 0.4677 - val_loss: 1.1006 - val_accuracy: 0.3822\n",
      "Epoch 36/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0044 - accuracy: 0.4740 - val_loss: 1.1044 - val_accuracy: 0.3656\n",
      "Epoch 37/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0117 - accuracy: 0.4746 - val_loss: 1.1072 - val_accuracy: 0.3634\n",
      "Epoch 38/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0024 - accuracy: 0.4716 - val_loss: 1.1026 - val_accuracy: 0.3822\n",
      "Epoch 39/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9986 - accuracy: 0.4825 - val_loss: 1.1073 - val_accuracy: 0.3667\n",
      "Epoch 40/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 1.0012 - accuracy: 0.4776 - val_loss: 1.1118 - val_accuracy: 0.3205\n",
      "Epoch 41/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9915 - accuracy: 0.4945 - val_loss: 1.1113 - val_accuracy: 0.3458\n",
      "Epoch 42/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.9890 - accuracy: 0.4925 - val_loss: 1.1095 - val_accuracy: 0.3337\n",
      "Epoch 43/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.9878 - accuracy: 0.4860 - val_loss: 1.1148 - val_accuracy: 0.3326\n",
      "Epoch 44/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.9819 - accuracy: 0.4983 - val_loss: 1.1178 - val_accuracy: 0.3403\n",
      "Epoch 45/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9761 - accuracy: 0.5003 - val_loss: 1.1085 - val_accuracy: 0.3370\n",
      "Epoch 46/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9815 - accuracy: 0.4949 - val_loss: 1.1138 - val_accuracy: 0.3469\n",
      "Epoch 47/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9750 - accuracy: 0.5043 - val_loss: 1.1110 - val_accuracy: 0.3469\n",
      "Epoch 48/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9672 - accuracy: 0.5021 - val_loss: 1.1142 - val_accuracy: 0.3458\n",
      "Epoch 49/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9608 - accuracy: 0.5107 - val_loss: 1.1185 - val_accuracy: 0.3502\n",
      "Epoch 50/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.9609 - accuracy: 0.5141 - val_loss: 1.1185 - val_accuracy: 0.3447\n",
      "Epoch 51/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9597 - accuracy: 0.5105 - val_loss: 1.1240 - val_accuracy: 0.3469\n",
      "Epoch 52/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9500 - accuracy: 0.5288 - val_loss: 1.1173 - val_accuracy: 0.3524\n",
      "Epoch 53/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9560 - accuracy: 0.5189 - val_loss: 1.1182 - val_accuracy: 0.3546\n",
      "Epoch 54/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9491 - accuracy: 0.5224 - val_loss: 1.1324 - val_accuracy: 0.3348\n",
      "Epoch 55/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9412 - accuracy: 0.5241 - val_loss: 1.1423 - val_accuracy: 0.3282\n",
      "Epoch 56/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9426 - accuracy: 0.5270 - val_loss: 1.1324 - val_accuracy: 0.3480\n",
      "Epoch 57/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9368 - accuracy: 0.5321 - val_loss: 1.1364 - val_accuracy: 0.3392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9362 - accuracy: 0.5335 - val_loss: 1.1279 - val_accuracy: 0.3337\n",
      "Epoch 59/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9335 - accuracy: 0.5315 - val_loss: 1.1353 - val_accuracy: 0.3370\n",
      "Epoch 60/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9210 - accuracy: 0.5439 - val_loss: 1.1360 - val_accuracy: 0.3304\n",
      "Epoch 61/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9319 - accuracy: 0.5328 - val_loss: 1.1322 - val_accuracy: 0.3447\n",
      "Epoch 62/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9257 - accuracy: 0.5405 - val_loss: 1.1384 - val_accuracy: 0.3260\n",
      "Epoch 63/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9234 - accuracy: 0.5342 - val_loss: 1.1452 - val_accuracy: 0.3348\n",
      "Epoch 64/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.9090 - accuracy: 0.5559 - val_loss: 1.1463 - val_accuracy: 0.3436\n",
      "Epoch 65/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9055 - accuracy: 0.5461 - val_loss: 1.1440 - val_accuracy: 0.3458\n",
      "Epoch 66/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9083 - accuracy: 0.5552 - val_loss: 1.1591 - val_accuracy: 0.3271\n",
      "Epoch 67/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.9122 - accuracy: 0.5504 - val_loss: 1.1569 - val_accuracy: 0.3172\n",
      "Epoch 68/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.9073 - accuracy: 0.5519 - val_loss: 1.1565 - val_accuracy: 0.3205\n",
      "Epoch 69/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.9110 - accuracy: 0.5456 - val_loss: 1.1467 - val_accuracy: 0.3227\n",
      "Epoch 70/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.9017 - accuracy: 0.5546 - val_loss: 1.1599 - val_accuracy: 0.3337\n",
      "Epoch 71/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8854 - accuracy: 0.5656 - val_loss: 1.1675 - val_accuracy: 0.3337\n",
      "Epoch 72/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8940 - accuracy: 0.5664 - val_loss: 1.1643 - val_accuracy: 0.3392\n",
      "Epoch 73/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8928 - accuracy: 0.5633 - val_loss: 1.1650 - val_accuracy: 0.3480\n",
      "Epoch 74/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8879 - accuracy: 0.5652 - val_loss: 1.1640 - val_accuracy: 0.3293\n",
      "Epoch 75/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8947 - accuracy: 0.5602 - val_loss: 1.1636 - val_accuracy: 0.3161\n",
      "Epoch 76/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8857 - accuracy: 0.5644 - val_loss: 1.1674 - val_accuracy: 0.3304\n",
      "Epoch 77/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8732 - accuracy: 0.5726 - val_loss: 1.1750 - val_accuracy: 0.3205\n",
      "Epoch 78/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8855 - accuracy: 0.5723 - val_loss: 1.1725 - val_accuracy: 0.3106\n",
      "Epoch 79/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8743 - accuracy: 0.5724 - val_loss: 1.1725 - val_accuracy: 0.3216\n",
      "Epoch 80/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8689 - accuracy: 0.5776 - val_loss: 1.1840 - val_accuracy: 0.3326\n",
      "Epoch 81/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8759 - accuracy: 0.5748 - val_loss: 1.1702 - val_accuracy: 0.3392\n",
      "Epoch 82/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8604 - accuracy: 0.5857 - val_loss: 1.1782 - val_accuracy: 0.3304\n",
      "Epoch 83/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8646 - accuracy: 0.5811 - val_loss: 1.1690 - val_accuracy: 0.3414\n",
      "Epoch 84/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8580 - accuracy: 0.5787 - val_loss: 1.1761 - val_accuracy: 0.3282\n",
      "Epoch 85/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8572 - accuracy: 0.5827 - val_loss: 1.1974 - val_accuracy: 0.3249\n",
      "Epoch 86/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8569 - accuracy: 0.5840 - val_loss: 1.1930 - val_accuracy: 0.3172\n",
      "Epoch 87/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8637 - accuracy: 0.5890 - val_loss: 1.1742 - val_accuracy: 0.3282\n",
      "Epoch 88/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8472 - accuracy: 0.5897 - val_loss: 1.1823 - val_accuracy: 0.3216\n",
      "Epoch 89/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8439 - accuracy: 0.5969 - val_loss: 1.1924 - val_accuracy: 0.3304\n",
      "Epoch 90/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8459 - accuracy: 0.5911 - val_loss: 1.1873 - val_accuracy: 0.3326\n",
      "Epoch 91/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8435 - accuracy: 0.5961 - val_loss: 1.1893 - val_accuracy: 0.3282\n",
      "Epoch 92/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8422 - accuracy: 0.5938 - val_loss: 1.2111 - val_accuracy: 0.3205\n",
      "Epoch 93/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8352 - accuracy: 0.5973 - val_loss: 1.2038 - val_accuracy: 0.3216\n",
      "Epoch 94/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8377 - accuracy: 0.5946 - val_loss: 1.1957 - val_accuracy: 0.3238\n",
      "Epoch 95/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8336 - accuracy: 0.6012 - val_loss: 1.2036 - val_accuracy: 0.3392\n",
      "Epoch 96/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8185 - accuracy: 0.6115 - val_loss: 1.2031 - val_accuracy: 0.3590\n",
      "Epoch 97/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8387 - accuracy: 0.5935 - val_loss: 1.1820 - val_accuracy: 0.3447\n",
      "Epoch 98/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8296 - accuracy: 0.6073 - val_loss: 1.2055 - val_accuracy: 0.3304\n",
      "Epoch 99/100\n",
      "511/511 [==============================] - 1s 1ms/step - loss: 0.8267 - accuracy: 0.6078 - val_loss: 1.2056 - val_accuracy: 0.3139\n",
      "Epoch 100/100\n",
      "511/511 [==============================] - 1s 2ms/step - loss: 0.8233 - accuracy: 0.6053 - val_loss: 1.1999 - val_accuracy: 0.3304\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 1.2167 - accuracy: 0.3288\n",
      "Accuracy del Modelo 1: 0.33\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(y_train_onehot.shape[1], activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history1 = model1.fit(X_train_scaled, y_train_onehot, epochs=100, batch_size=16, validation_split=0.1, verbose=1)\n",
    "_, acc_nn1 = model1.evaluate(X_test_scaled, y_test_onehot)\n",
    "print(f'Accuracy del Modelo 1: {acc_nn1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d666d6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1807 - accuracy: 0.3489 - val_loss: 1.1357 - val_accuracy: 0.3658\n",
      "Epoch 2/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1152 - accuracy: 0.3818 - val_loss: 1.1146 - val_accuracy: 0.3846\n",
      "Epoch 3/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0931 - accuracy: 0.3972 - val_loss: 1.1062 - val_accuracy: 0.3989\n",
      "Epoch 4/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0808 - accuracy: 0.4115 - val_loss: 1.1021 - val_accuracy: 0.4006\n",
      "Epoch 5/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0725 - accuracy: 0.4215 - val_loss: 1.0998 - val_accuracy: 0.4088\n",
      "Epoch 6/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0660 - accuracy: 0.4332 - val_loss: 1.0994 - val_accuracy: 0.4011\n",
      "Epoch 7/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0603 - accuracy: 0.4384 - val_loss: 1.0996 - val_accuracy: 0.4055\n",
      "Epoch 8/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0556 - accuracy: 0.4406 - val_loss: 1.0990 - val_accuracy: 0.4050\n",
      "Epoch 9/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0515 - accuracy: 0.4482 - val_loss: 1.0991 - val_accuracy: 0.4000\n",
      "Epoch 10/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0473 - accuracy: 0.4490 - val_loss: 1.0992 - val_accuracy: 0.4050\n",
      "Epoch 11/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0432 - accuracy: 0.4570 - val_loss: 1.1006 - val_accuracy: 0.4039\n",
      "Epoch 12/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0398 - accuracy: 0.4609 - val_loss: 1.1002 - val_accuracy: 0.3989\n",
      "Epoch 13/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0362 - accuracy: 0.4649 - val_loss: 1.1007 - val_accuracy: 0.3956\n",
      "Epoch 14/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0327 - accuracy: 0.4639 - val_loss: 1.1014 - val_accuracy: 0.3983\n",
      "Epoch 15/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0289 - accuracy: 0.4711 - val_loss: 1.1025 - val_accuracy: 0.4006\n",
      "Epoch 16/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0257 - accuracy: 0.4749 - val_loss: 1.1034 - val_accuracy: 0.3928\n",
      "Epoch 17/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0220 - accuracy: 0.4782 - val_loss: 1.1040 - val_accuracy: 0.3956\n",
      "Epoch 18/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0186 - accuracy: 0.4799 - val_loss: 1.1062 - val_accuracy: 0.3978\n",
      "Epoch 19/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0147 - accuracy: 0.4858 - val_loss: 1.1066 - val_accuracy: 0.3912\n",
      "Epoch 20/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0108 - accuracy: 0.4904 - val_loss: 1.1081 - val_accuracy: 0.3945\n",
      "Epoch 21/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0071 - accuracy: 0.4946 - val_loss: 1.1105 - val_accuracy: 0.3934\n",
      "Epoch 22/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0032 - accuracy: 0.4983 - val_loss: 1.1114 - val_accuracy: 0.3934\n",
      "Epoch 23/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9991 - accuracy: 0.5019 - val_loss: 1.1123 - val_accuracy: 0.3923\n",
      "Epoch 24/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9948 - accuracy: 0.5045 - val_loss: 1.1151 - val_accuracy: 0.3884\n",
      "Epoch 25/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.9905 - accuracy: 0.5120 - val_loss: 1.1161 - val_accuracy: 0.3928\n",
      "Epoch 26/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.9859 - accuracy: 0.5185 - val_loss: 1.1183 - val_accuracy: 0.3884\n",
      "Epoch 27/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9814 - accuracy: 0.5258 - val_loss: 1.1199 - val_accuracy: 0.3835\n",
      "Epoch 28/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9768 - accuracy: 0.5306 - val_loss: 1.1226 - val_accuracy: 0.3818\n",
      "Epoch 29/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9717 - accuracy: 0.5316 - val_loss: 1.1249 - val_accuracy: 0.3818\n",
      "Epoch 30/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9666 - accuracy: 0.5393 - val_loss: 1.1276 - val_accuracy: 0.3769\n",
      "Epoch 31/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9615 - accuracy: 0.5437 - val_loss: 1.1297 - val_accuracy: 0.3796\n",
      "Epoch 32/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9559 - accuracy: 0.5486 - val_loss: 1.1327 - val_accuracy: 0.3719\n",
      "Epoch 33/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9501 - accuracy: 0.5569 - val_loss: 1.1378 - val_accuracy: 0.3725\n",
      "Epoch 34/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9444 - accuracy: 0.5598 - val_loss: 1.1376 - val_accuracy: 0.3774\n",
      "Epoch 35/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9385 - accuracy: 0.5634 - val_loss: 1.1413 - val_accuracy: 0.3730\n",
      "Epoch 36/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9323 - accuracy: 0.5670 - val_loss: 1.1456 - val_accuracy: 0.3725\n",
      "Epoch 37/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9255 - accuracy: 0.5722 - val_loss: 1.1478 - val_accuracy: 0.3725\n",
      "Epoch 38/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9188 - accuracy: 0.5827 - val_loss: 1.1520 - val_accuracy: 0.3741\n",
      "Epoch 39/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9114 - accuracy: 0.5847 - val_loss: 1.1582 - val_accuracy: 0.3758\n",
      "Epoch 40/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9048 - accuracy: 0.5898 - val_loss: 1.1629 - val_accuracy: 0.3719\n",
      "Epoch 41/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.8972 - accuracy: 0.5998 - val_loss: 1.1675 - val_accuracy: 0.3758\n",
      "Epoch 42/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.8893 - accuracy: 0.6025 - val_loss: 1.1708 - val_accuracy: 0.3719\n",
      "Epoch 43/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.8813 - accuracy: 0.6097 - val_loss: 1.1738 - val_accuracy: 0.3741\n",
      "Epoch 44/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.8727 - accuracy: 0.6134 - val_loss: 1.1814 - val_accuracy: 0.3708\n",
      "Epoch 45/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.8644 - accuracy: 0.6215 - val_loss: 1.1848 - val_accuracy: 0.3653\n",
      "Epoch 46/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.8561 - accuracy: 0.6266 - val_loss: 1.1931 - val_accuracy: 0.3642\n",
      "Epoch 47/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.8467 - accuracy: 0.6349 - val_loss: 1.2003 - val_accuracy: 0.3625\n",
      "Epoch 48/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.8374 - accuracy: 0.6404 - val_loss: 1.2044 - val_accuracy: 0.3664\n",
      "Epoch 49/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.8274 - accuracy: 0.6498 - val_loss: 1.2125 - val_accuracy: 0.3669\n",
      "Epoch 50/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.8186 - accuracy: 0.6561 - val_loss: 1.2236 - val_accuracy: 0.3758\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 1.2170 - accuracy: 0.3878\n",
      "Accuracy del Modelo 2: 0.39\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(100, input_dim=X_train_scaled.shape[1], activation='tanh'))\n",
    "model2.add(Dense(50, activation='tanh'))\n",
    "model2.add(Dense(y_train_onehot.shape[1], activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(X_train_scaled, y_train_onehot, epochs=50, batch_size=64, validation_split=0.2, verbose=1)\n",
    "_, acc_nn2 = model2.evaluate(X_test_scaled, y_test_onehot)\n",
    "print(f'Accuracy del Modelo 2: {acc_nn2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad88eec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 1.2151 - accuracy: 0.3578 - val_loss: 1.1482 - val_accuracy: 0.3630\n",
      "Epoch 2/75\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 1.0708 - accuracy: 0.4354 - val_loss: 1.1287 - val_accuracy: 0.3872\n",
      "Epoch 3/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 1.0378 - accuracy: 0.4684 - val_loss: 1.1395 - val_accuracy: 0.3556\n",
      "Epoch 4/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 1.0174 - accuracy: 0.4853 - val_loss: 1.1612 - val_accuracy: 0.3644\n",
      "Epoch 5/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.9970 - accuracy: 0.5077 - val_loss: 1.1628 - val_accuracy: 0.3711\n",
      "Epoch 6/75\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.9717 - accuracy: 0.5303 - val_loss: 1.1827 - val_accuracy: 0.3762\n",
      "Epoch 7/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.9404 - accuracy: 0.5508 - val_loss: 1.2274 - val_accuracy: 0.3490\n",
      "Epoch 8/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.9162 - accuracy: 0.5677 - val_loss: 1.2465 - val_accuracy: 0.3446\n",
      "Epoch 9/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.8896 - accuracy: 0.5919 - val_loss: 1.2609 - val_accuracy: 0.3586\n",
      "Epoch 10/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.8578 - accuracy: 0.6032 - val_loss: 1.2955 - val_accuracy: 0.3600\n",
      "Epoch 11/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.8372 - accuracy: 0.6240 - val_loss: 1.2930 - val_accuracy: 0.3659\n",
      "Epoch 12/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.8080 - accuracy: 0.6395 - val_loss: 1.3588 - val_accuracy: 0.3446\n",
      "Epoch 13/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.7895 - accuracy: 0.6513 - val_loss: 1.3898 - val_accuracy: 0.3564\n",
      "Epoch 14/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.7638 - accuracy: 0.6645 - val_loss: 1.4278 - val_accuracy: 0.3630\n",
      "Epoch 15/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.7439 - accuracy: 0.6769 - val_loss: 1.4295 - val_accuracy: 0.3659\n",
      "Epoch 16/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.6880 - val_loss: 1.4605 - val_accuracy: 0.3542\n",
      "Epoch 17/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.6946 - val_loss: 1.4940 - val_accuracy: 0.3711\n",
      "Epoch 18/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.7059 - val_loss: 1.5523 - val_accuracy: 0.3564\n",
      "Epoch 19/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.7085 - val_loss: 1.5928 - val_accuracy: 0.3446\n",
      "Epoch 20/75\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.7270 - val_loss: 1.6084 - val_accuracy: 0.3483\n",
      "Epoch 21/75\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.6295 - accuracy: 0.7300 - val_loss: 1.6440 - val_accuracy: 0.3431\n",
      "Epoch 22/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6252 - accuracy: 0.7373 - val_loss: 1.6578 - val_accuracy: 0.3586\n",
      "Epoch 23/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6121 - accuracy: 0.7422 - val_loss: 1.6671 - val_accuracy: 0.3446\n",
      "Epoch 24/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6066 - accuracy: 0.7413 - val_loss: 1.6990 - val_accuracy: 0.3519\n",
      "Epoch 25/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5776 - accuracy: 0.7610 - val_loss: 1.7559 - val_accuracy: 0.3696\n",
      "Epoch 26/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5764 - accuracy: 0.7624 - val_loss: 1.7982 - val_accuracy: 0.3564\n",
      "Epoch 27/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5636 - accuracy: 0.7702 - val_loss: 1.8025 - val_accuracy: 0.3439\n",
      "Epoch 28/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5544 - accuracy: 0.7766 - val_loss: 1.8150 - val_accuracy: 0.3586\n",
      "Epoch 29/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7772 - val_loss: 1.8812 - val_accuracy: 0.3725\n",
      "Epoch 30/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7794 - val_loss: 1.8480 - val_accuracy: 0.3747\n",
      "Epoch 31/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7797 - val_loss: 1.9004 - val_accuracy: 0.3542\n",
      "Epoch 32/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5233 - accuracy: 0.7863 - val_loss: 1.9137 - val_accuracy: 0.3490\n",
      "Epoch 33/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4991 - accuracy: 0.7938 - val_loss: 1.9276 - val_accuracy: 0.3681\n",
      "Epoch 34/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5041 - accuracy: 0.7943 - val_loss: 1.9608 - val_accuracy: 0.3652\n",
      "Epoch 35/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4815 - accuracy: 0.8025 - val_loss: 1.9850 - val_accuracy: 0.3475\n",
      "Epoch 36/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5024 - accuracy: 0.7925 - val_loss: 1.9757 - val_accuracy: 0.3578\n",
      "Epoch 37/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4837 - accuracy: 0.8021 - val_loss: 2.0592 - val_accuracy: 0.3439\n",
      "Epoch 38/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.8106 - val_loss: 2.0432 - val_accuracy: 0.3549\n",
      "Epoch 39/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4663 - accuracy: 0.8126 - val_loss: 2.0839 - val_accuracy: 0.3556\n",
      "Epoch 40/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4667 - accuracy: 0.8112 - val_loss: 2.0732 - val_accuracy: 0.3490\n",
      "Epoch 41/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.8209 - val_loss: 2.1779 - val_accuracy: 0.3343\n",
      "Epoch 42/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4588 - accuracy: 0.8166 - val_loss: 2.1217 - val_accuracy: 0.3350\n",
      "Epoch 43/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.8195 - val_loss: 2.1230 - val_accuracy: 0.3512\n",
      "Epoch 44/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.8221 - val_loss: 2.1511 - val_accuracy: 0.3439\n",
      "Epoch 45/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8239 - val_loss: 2.2141 - val_accuracy: 0.3615\n",
      "Epoch 46/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4313 - accuracy: 0.8230 - val_loss: 2.1731 - val_accuracy: 0.3696\n",
      "Epoch 47/75\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.4372 - accuracy: 0.8262 - val_loss: 2.2185 - val_accuracy: 0.3556\n",
      "Epoch 48/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4029 - accuracy: 0.8401 - val_loss: 2.2404 - val_accuracy: 0.3615\n",
      "Epoch 49/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.8297 - val_loss: 2.2865 - val_accuracy: 0.3586\n",
      "Epoch 50/75\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.4141 - accuracy: 0.8300 - val_loss: 2.2611 - val_accuracy: 0.3659\n",
      "Epoch 51/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4053 - accuracy: 0.8415 - val_loss: 2.2702 - val_accuracy: 0.3666\n",
      "Epoch 52/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4106 - accuracy: 0.8370 - val_loss: 2.2511 - val_accuracy: 0.3637\n",
      "Epoch 53/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4122 - accuracy: 0.8344 - val_loss: 2.2897 - val_accuracy: 0.3578\n",
      "Epoch 54/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3858 - accuracy: 0.8493 - val_loss: 2.3114 - val_accuracy: 0.3644\n",
      "Epoch 55/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3932 - accuracy: 0.8390 - val_loss: 2.3211 - val_accuracy: 0.3571\n",
      "Epoch 56/75\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.3716 - accuracy: 0.8540 - val_loss: 2.3738 - val_accuracy: 0.3556\n",
      "Epoch 57/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4007 - accuracy: 0.8349 - val_loss: 2.3593 - val_accuracy: 0.3519\n",
      "Epoch 58/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3920 - accuracy: 0.8434 - val_loss: 2.3843 - val_accuracy: 0.3600\n",
      "Epoch 59/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8537 - val_loss: 2.3917 - val_accuracy: 0.3740\n",
      "Epoch 60/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3716 - accuracy: 0.8480 - val_loss: 2.4132 - val_accuracy: 0.3497\n",
      "Epoch 61/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3762 - accuracy: 0.8519 - val_loss: 2.4633 - val_accuracy: 0.3505\n",
      "Epoch 62/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.8550 - val_loss: 2.4674 - val_accuracy: 0.3431\n",
      "Epoch 63/75\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.3615 - accuracy: 0.8587 - val_loss: 2.4178 - val_accuracy: 0.3652\n",
      "Epoch 64/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3689 - accuracy: 0.8563 - val_loss: 2.4069 - val_accuracy: 0.3505\n",
      "Epoch 65/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3749 - accuracy: 0.8479 - val_loss: 2.4188 - val_accuracy: 0.3490\n",
      "Epoch 66/75\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.3594 - accuracy: 0.8549 - val_loss: 2.4557 - val_accuracy: 0.3527\n",
      "Epoch 67/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3492 - accuracy: 0.8614 - val_loss: 2.5522 - val_accuracy: 0.3600\n",
      "Epoch 68/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3497 - accuracy: 0.8602 - val_loss: 2.5161 - val_accuracy: 0.3549\n",
      "Epoch 69/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8626 - val_loss: 2.5402 - val_accuracy: 0.3637\n",
      "Epoch 70/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3654 - accuracy: 0.8541 - val_loss: 2.5246 - val_accuracy: 0.3586\n",
      "Epoch 71/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8671 - val_loss: 2.5145 - val_accuracy: 0.3608\n",
      "Epoch 72/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3551 - accuracy: 0.8601 - val_loss: 2.5494 - val_accuracy: 0.3608\n",
      "Epoch 73/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8640 - val_loss: 2.5969 - val_accuracy: 0.3637\n",
      "Epoch 74/75\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.3249 - accuracy: 0.8694 - val_loss: 2.5824 - val_accuracy: 0.3534\n",
      "Epoch 75/75\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.3320 - accuracy: 0.8733 - val_loss: 2.6807 - val_accuracy: 0.3475\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2.6136 - accuracy: 0.3491\n",
      "Accuracy del Modelo 3: 0.35\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu', kernel_initializer=HeNormal()))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dense(64, activation='relu', kernel_initializer=HeNormal()))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dense(y_train_onehot.shape[1], activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history3 = model3.fit(X_train_scaled, y_train_onehot, epochs=75, batch_size=20, validation_split=0.15, verbose=1)\n",
    "_, acc_nn3 = model3.evaluate(X_test_scaled, y_test_onehot)\n",
    "print(f'Accuracy del Modelo 3: {acc_nn3:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33067f17",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658849fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de SVM: 0.44\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='auto')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f'Accuracy de SVM: {acc_svm:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d946d102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de SVM ajustado: 0.38\n"
     ]
    }
   ],
   "source": [
    "# Cambio de hiperparámetros: C más alto, gamma 'scale' y probando un kernel polinomial\n",
    "svm_model_adjusted = SVC(kernel='poly', C=10.0, gamma='scale', degree=3)\n",
    "svm_model_adjusted.fit(X_train_scaled, y_train)\n",
    "y_pred_svm_adjusted = svm_model_adjusted.predict(X_test_scaled)\n",
    "\n",
    "acc_svm_adjusted = accuracy_score(y_test, y_pred_svm_adjusted)\n",
    "print(f'Accuracy de SVM ajustado: {acc_svm_adjusted:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e03dd",
   "metadata": {},
   "source": [
    "We optimize the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a41786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(SVC(), param_distributions, n_iter=10, cv=5, scoring='accuracy', verbose=1, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "print(f'Mejores hiperparámetros: {random_search.best_params_}')\n",
    "print(f'Mejor score de accuracy: {random_search.best_score_:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar el mejor modelo para hacer predicciones sobre el conjunto de prueba\n",
    "y_pred = grid_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy en el conjunto de prueba: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd3c09",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38de22e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de Random Forest: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Entrenar un modelo de Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)  # No necesita escalar los datos para Random Forest\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Accuracy de Random Forest: {acc_rf:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2154174",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4621df51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de XGBoost: 0.40\n"
     ]
    }
   ],
   "source": [
    "# Crear el objeto LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Ajustar el encoder a las etiquetas y transformarlas\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "# Ahora puedes usar estas etiquetas numéricas para entrenar XGBoost\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softprob', n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_clf.fit(X_train_scaled, y_train_encoded)\n",
    "y_pred_xgb = xgb_clf.predict(X_test_scaled)\n",
    "\n",
    "# Convertir predicciones numéricas de vuelta a etiquetas originales para la evaluación si es necesario\n",
    "y_pred_labels = encoder.inverse_transform(y_pred_xgb)\n",
    "\n",
    "# Evaluar el modelo\n",
    "acc_xgb = accuracy_score(y_test_encoded, y_pred_xgb)\n",
    "print(f'Accuracy de XGBoost: {acc_xgb:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb846a40",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e8e171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de Gradient Boosting: 0.42\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "\n",
    "acc_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f'Accuracy de Gradient Boosting: {acc_gb:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d5186",
   "metadata": {},
   "source": [
    "### Stacking (random forest and SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef8ed36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de Stacking: 0.44\n"
     ]
    }
   ],
   "source": [
    "# Definir los estimadores para el StackingClassifier\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),  # RandomForest\n",
    "    ('svc', SVC(kernel='rbf', C=1.0, gamma='auto', random_state=42))  # SVC con los parámetros específicos\n",
    "]\n",
    "\n",
    "# Configurar el StackingClassifier\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, \n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "# Entrenar el modelo Stacking\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predecir con el modelo Stacking\n",
    "y_pred_stack = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "acc_stack = accuracy_score(y_test, y_pred_stack)\n",
    "print(f'Accuracy de Stacking: {acc_stack:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e362e442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datos: nombres de los modelos y sus precisiones correspondientes\n",
    "model_names = ['Logistic Regression', 'Neural Network', 'SVM', 'Random Forest', 'XGBoost', 'Stacking (SVM & RF)']\n",
    "accuracies = [41, 39, 44, 42, 40, 44]  # Precisión en porcentaje\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "plt.figure(figsize=(10, 6))  # Tamaño de la figura\n",
    "plt.bar(model_names, accuracies, color='#A4E473')  # Usar un verde clarito para todas las barras\n",
    "\n",
    "# Añadir título y etiquetas a los ejes\n",
    "plt.title('Accuracy Comparison of Different Models')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "# Ajustar límites del eje y\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Eliminar los bordes superior y derecho\n",
    "ax = plt.gca()  # Obtener el contexto actual de los ejes\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Añadir etiquetas de texto sobre cada barra con la precisión\n",
    "for i in range(len(accuracies)):\n",
    "    plt.text(i, accuracies[i] + 1, f'{accuracies[i]}%', ha='center', va='bottom')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.xticks(rotation=45)  # Rotar los nombres de los modelos para mejor visualización\n",
    "plt.tight_layout()  # Ajustar automáticamente los parámetros de la subtrama\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
